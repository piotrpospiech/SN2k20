{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ćwiczenie 2** - sieć wielowarstwowa uczona metodą propagacji wstecznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random as random\n",
    "from scipy.special import softmax\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Network():\n",
    "    \n",
    "    # Utils\n",
    "    \n",
    "    def __generate_random_matrix(self, shape_x, shape_y, max_value=1):\n",
    "        return np.random.rand(shape_x, shape_y) * 2 * max_value - max_value\n",
    "    \n",
    "    def __generate_random_number(self, max_value=0.1):\n",
    "        return random.random() * 2 * max_value - max_value\n",
    "    \n",
    "    # Constructor\n",
    "    \n",
    "    def __init__(self, layer_shapes, function, max_value=1):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.function = function\n",
    "        \n",
    "        for layer_shape in layer_shapes:\n",
    "            shape_x, shape_y = layer_shape\n",
    "            self.weights.append(self.__generate_random_matrix(shape_x, shape_y, max_value=max_value))\n",
    "            self.biases.append(self.__generate_random_number())\n",
    "        \n",
    "    # Code\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(X):\n",
    "        return X / 254\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_result(prediction):\n",
    "        return np.where(prediction == np.max(prediction))[0][0]\n",
    "    \n",
    "    def __sigmoid(self, z, deriv=False):\n",
    "        if deriv:\n",
    "            sigmoid = self.__sigmoid(z)\n",
    "            return sigmoid * (1 - sigmoid)\n",
    "        else:\n",
    "            return 1.0 / (1.0 + np.exp(-z))\n",
    "        \n",
    "    def __tangens(self, z, deriv=False):\n",
    "        if deriv:\n",
    "            tangens = self.__tangens(z)\n",
    "            return tangens * (1 - tangens)\n",
    "        else:\n",
    "            return (2 / (1 + np.exp(-2 * z))) - 1\n",
    "        \n",
    "    def __relu(self, z, deriv=False):\n",
    "        if deriv:\n",
    "            return 1 / (1 + np.exp(-z / np.max(z))) if np.mean(z) > 1000 else 1 / (1 + np.exp(-z))\n",
    "        else:\n",
    "            return np.log(1 + np.exp(z / np.max(z))) if np.mean(z) > 1000 else np.log(1 + np.exp(z))\n",
    "        \n",
    "    def __activation_function(self, z, deriv=False):\n",
    "        if self.function == 'sigmoid':\n",
    "            return self.__sigmoid(z, deriv)\n",
    "        elif self.function == 'tangens':\n",
    "            return self.__tangens(z, deriv)\n",
    "        else:\n",
    "            return self.__relu(z, deriv)\n",
    "    \n",
    "    def __softmax_derivative(self, x):\n",
    "        return softmax(x) * (1 - softmax(x))\n",
    "    \n",
    "    def forward(self, X, predict=False):\n",
    "        \n",
    "        aa = [X]\n",
    "        zz = [X]\n",
    "        a = X\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = a @ w + b\n",
    "            \n",
    "            if i == len(self.weights) - 1:\n",
    "                a = softmax(z, axis=1)\n",
    "            else:\n",
    "                a = self.__activation_function(z)\n",
    "                \n",
    "            aa.append(a)\n",
    "            zz.append(z)\n",
    "            \n",
    "        if predict:\n",
    "            return a\n",
    "        else:\n",
    "            return aa, zz\n",
    "        \n",
    "    def backpropagation(self, learning_rate, y, aa, zz):\n",
    "        \n",
    "        cost = np.sum((y - aa[-1]) ** 2) / 2\n",
    "    \n",
    "        deltas = []\n",
    "        errors = []\n",
    "        output_error = y - aa[-1]\n",
    "        errors.append(output_error)\n",
    "        \n",
    "        delta = output_error * self.__softmax_derivative(aa[-1])\n",
    "        deltas.append(delta)\n",
    "        \n",
    "        for i in range(1, len(aa) - 1):\n",
    "            hidden_error = delta @ self.weights[-i].T\n",
    "            errors.append(hidden_error)\n",
    "            delta = hidden_error * self.__activation_function(aa[-(i + 1)], True)\n",
    "            deltas.append(delta)\n",
    "        \n",
    "        return cost, deltas, errors\n",
    "    \n",
    "    def train(self, X, y, learning_rate, batch_size, max_epochs, max_error):\n",
    "    \n",
    "        costs = []\n",
    "        batch_index = 0\n",
    "        epochs = 0\n",
    "        \n",
    "        for i in range(max_epochs):\n",
    "            \n",
    "            batch_X = X[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "            batch_y = y[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "            batch_index += 1\n",
    "            \n",
    "            if batch_index * batch_size >= len(X):\n",
    "                batch_index = 0\n",
    "            \n",
    "            aa, zz = self.forward(batch_X)\n",
    "            cost, deltas, errors = self.backpropagation(learning_rate, batch_y, aa, zz)\n",
    "\n",
    "            for j in range(len(self.weights)):\n",
    "                self.weights[j] += learning_rate * aa[j].T @ deltas[-(j + 1)]\n",
    "                self.biases[j] += learning_rate * np.mean(deltas[-(j + 1)])\n",
    "\n",
    "            costs.append(cost)\n",
    "            \n",
    "            epochs += 1\n",
    "            \n",
    "            if (cost / batch_size < max_error):\n",
    "                break\n",
    "\n",
    "#             if i % 1000 == 0:\n",
    "#                 print(f'Iteration: {i}, error: {cost / batch_size}')\n",
    "                \n",
    "        return costs, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for X_matrix in train_X:\n",
    "    X.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X = np.array(X, dtype=np.float128)\n",
    "    \n",
    "labels = []\n",
    "for y in train_y:\n",
    "    label = np.zeros(10)\n",
    "    label[y] = 1\n",
    "    labels.append(label)\n",
    "labels = np.array(labels, dtype=np.float128)\n",
    "\n",
    "X_test = []\n",
    "for X_matrix in test_X[0:-3000]:\n",
    "    X_test.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X_test = np.array(X_test, dtype=np.float128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-be9d0ca73408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     costs, epoch = network.train(X, \n\u001b[0m\u001b[1;32m     15\u001b[0m                   \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                   \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0ea4843945df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, learning_rate, batch_size, max_epochs, max_error)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0ea4843945df>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, predict)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 15), (15, 10)]\n",
    "\n",
    "total_costs = []\n",
    "epochs = 0\n",
    "accs = 0\n",
    "times = 10\n",
    "\n",
    "for i in range(times):\n",
    "    network = Network(layer_shapes=layer_shapes, function='sigmoid')\n",
    "\n",
    "    costs, epoch = network.train(X, \n",
    "                  labels, \n",
    "                  learning_rate=0.1, \n",
    "                  max_epochs=10000,\n",
    "                  batch_size=32,\n",
    "                  max_error=0.05)\n",
    "\n",
    "    if len(total_costs) == 0:\n",
    "        total_costs = costs\n",
    "    else:\n",
    "        total_costs = (np.array(total_costs) + np.array(costs)).tolist()\n",
    "\n",
    "    epochs += epoch\n",
    "    \n",
    "    z = network.forward(X_test, predict=True)\n",
    "\n",
    "    sum = 0\n",
    "    for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "        if Network.get_result(z_i) == label_i:\n",
    "            sum +=1\n",
    "            \n",
    "    accs += round(sum / len(z) * 100, 2)\n",
    "            \n",
    "total_costs = (np.array(total_costs) / times).tolist()\n",
    "\n",
    "plt.plot(total_costs)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.show()\n",
    "\n",
    "print(f'Epochs: {epochs / times}')\n",
    "print(f'Accuracy: {accs / times}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for X_matrix in test_X:\n",
    "    X.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X = np.array(X)\n",
    "\n",
    "z = network.forward(X, predict=True)\n",
    "\n",
    "sum = 0\n",
    "for z_i, label_i in zip(z, test_y):\n",
    "    if Network.get_result(z_i) == label_i:\n",
    "        sum +=1\n",
    "        \n",
    "print(f'Accuracy: {round(sum / len(z) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for X_matrix in train_X:\n",
    "    X.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X = np.array(X, dtype=np.float128)\n",
    "    \n",
    "labels = []\n",
    "for y in train_y:\n",
    "    label = np.zeros(10)\n",
    "    label[y] = 1\n",
    "    labels.append(label)\n",
    "labels = np.array(labels, dtype=np.float128)\n",
    "\n",
    "X_test = []\n",
    "for X_matrix in test_X[0:-3000]:\n",
    "    X_test.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X_test = np.array(X_test, dtype=np.float128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-590f648a5723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         costs, epoch = network.train(X, \n\u001b[0m\u001b[1;32m     24\u001b[0m                       \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-0ea4843945df>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, learning_rate, batch_size, max_epochs, max_error)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test Batch Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 15), (15, 10)]\n",
    "batches = [2, 4, 8, 16, 32, 64, 128]\n",
    "learning_rate = 0.1\n",
    "\n",
    "df = pd.DataFrame(columns=['Batch', 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for batch in batches:\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        network = Network(layer_shapes=layer_shapes, function=function)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=learning_rate, \n",
    "                      max_epochs=1000,\n",
    "                      batch_size=batch,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Batch:', batch, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Batch': batch, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-batch-size-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test learning rate Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 20), (20, 15), (15, 10)]\n",
    "learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "df = pd.DataFrame(columns=['Learning rate', 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        network = Network(layer_shapes=layer_shapes, function=function)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=learning_rate, \n",
    "                      max_epochs=10000,\n",
    "                      batch_size=32,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Learning rate:', learning_rate, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Learning rate': learning_rate, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-learning-rate-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Hidden Layer Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 600, 700]\n",
    "\n",
    "df = pd.DataFrame(columns=['Layer size', 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for layer_size in layer_sizes:\n",
    "    \n",
    "    layer_shapes=[(784, layer_size), (layer_size, 10)]\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        network = Network(layer_shapes=layer_shapes, function='sigmoid')\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=0.1, \n",
    "                      max_epochs=1000,\n",
    "                      batch_size=32,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Layer size:', layer_size, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Layer size': layer_size, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-layer-size-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Initial Weight values\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "w_max_values = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Weights' range\", 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for max_value in w_max_values:\n",
    "    \n",
    "    layer_shapes=[(784, 15), (15, 10)]\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        network = Network(layer_shapes=layer_shapes, function='sigmoid', max_value=max_value)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=0.1, \n",
    "                      max_epochs=10000,\n",
    "                      batch_size=32,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print(\"Weights' range:\", (-max_value, max_value), ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({\"Weights' range:\": (-max_value, max_value), 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-weights-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Batch Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 15), (15, 10)]\n",
    "batches = [2, 4, 8, 16, 32, 64, 128]\n",
    "learning_rate = 0.1\n",
    "\n",
    "df = pd.DataFrame(columns=['Function', 'Epochs', 'Accuracy'])\n",
    "functions = ['relu', 'sigmoid']\n",
    "\n",
    "for function in functions:\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(20):\n",
    "        network = Network(layer_shapes=layer_shapes, function=function)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=0.1, \n",
    "                      max_epochs=5000,\n",
    "                      batch_size=64,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Function:', function, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Function': function, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/function-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
