{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ćwiczenie 2** - sieć wielowarstwowa uczona metodą propagacji wstecznej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random as random\n",
    "from scipy.special import softmax\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "class Network():\n",
    "    \n",
    "    # Utils\n",
    "    \n",
    "    def __generate_random_matrix(self, shape_x, shape_y, max_value=1):\n",
    "        return np.random.rand(shape_x, shape_y) * 2 * max_value - max_value\n",
    "    \n",
    "    def __generate_random_number(self, max_value=0.1):\n",
    "        return random.random() * 2 * max_value - max_value\n",
    "    \n",
    "    # Constructor\n",
    "    \n",
    "    def __init__(self, layer_shapes, function, max_value=1):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.function = function\n",
    "        \n",
    "        for layer_shape in layer_shapes:\n",
    "            shape_x, shape_y = layer_shape\n",
    "            self.weights.append(self.__generate_random_matrix(shape_x, shape_y, max_value=max_value))\n",
    "            self.biases.append(self.__generate_random_number())\n",
    "        \n",
    "    # Code\n",
    "    \n",
    "    @staticmethod\n",
    "    def normalize(X):\n",
    "        return X / 254\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_result(prediction):\n",
    "        return np.where(prediction == np.max(prediction))[0][0]\n",
    "    \n",
    "    def __sigmoid(self, z, deriv=False):\n",
    "        if deriv:\n",
    "            sigmoid = self.__sigmoid(z)\n",
    "            return sigmoid * (1 - sigmoid)\n",
    "        else:\n",
    "            return 1.0 / (1.0 + np.exp(-z))\n",
    "        \n",
    "    def __tangens(self, z, deriv=False):\n",
    "        if deriv:\n",
    "            tangens = self.__tangens(z)\n",
    "            return tangens * (1 - tangens)\n",
    "        else:\n",
    "            return (2 / (1 + np.exp(-2 * z))) - 1\n",
    "        \n",
    "    def __relu(self, z, deriv=False):\n",
    "        if deriv:\n",
    "            return 1 / (1 + np.exp(-z / np.max(z))) if np.mean(z) > 1000 else 1 / (1 + np.exp(-z))\n",
    "        else:\n",
    "            return np.log(1 + np.exp(z / np.max(z))) if np.mean(z) > 1000 else np.log(1 + np.exp(z))\n",
    "        \n",
    "    def __activation_function(self, z, deriv=False):\n",
    "        if self.function == 'sigmoid':\n",
    "            return self.__sigmoid(z, deriv)\n",
    "        elif self.function == 'tangens':\n",
    "            return self.__tangens(z, deriv)\n",
    "        else:\n",
    "            return self.__relu(z, deriv)\n",
    "    \n",
    "    def __softmax_derivative(self, x):\n",
    "        return softmax(x) * (1 - softmax(x))\n",
    "    \n",
    "    def forward(self, X, predict=False):\n",
    "        \n",
    "        aa = [X]\n",
    "        zz = [X]\n",
    "        a = X\n",
    "        \n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            z = a @ w + b\n",
    "            \n",
    "            if i == len(self.weights) - 1:\n",
    "                a = softmax(z, axis=1)\n",
    "            else:\n",
    "                a = self.__activation_function(z)\n",
    "                \n",
    "            aa.append(a)\n",
    "            zz.append(z)\n",
    "            \n",
    "        if predict:\n",
    "            return a\n",
    "        else:\n",
    "            return aa, zz\n",
    "        \n",
    "    def backpropagation(self, learning_rate, y, aa, zz):\n",
    "        \n",
    "#         delta = (y - aa[2]) * self.__softmax_derivative(aa[2])\n",
    "#         self.weights[1] += learning_rate * zz[1].T @ delta\n",
    "        \n",
    "#         delta2 = ((delta @ self.weights[1].T) - aa[1]) * self.__activation_function(aa[1], True)\n",
    "#         self.weights[0] = learning_rate * zz[0].T @ delta2\n",
    "        \n",
    "        cost = np.sum((y - aa[-1]) ** 2) / 2\n",
    "    \n",
    "        deltas = []\n",
    "        errors = []\n",
    "        output_error = y - aa[-1]\n",
    "        errors.append(output_error)\n",
    "        \n",
    "        delta = output_error * self.__softmax_derivative(aa[-1])\n",
    "        deltas.append(delta)\n",
    "        \n",
    "        for i in range(1, len(aa) - 1):\n",
    "            hidden_error = delta @ self.weights[-i].T\n",
    "            errors.append(hidden_error)\n",
    "            delta = hidden_error * self.__activation_function(aa[-(i + 1)], True)\n",
    "            deltas.append(delta)\n",
    "        \n",
    "        return cost, deltas, errors\n",
    "    \n",
    "    def train(self, X, y, learning_rate, batch_size, max_epochs, max_error):\n",
    "    \n",
    "        costs = []\n",
    "        batch_index = 0\n",
    "        epochs = 0\n",
    "        \n",
    "        for i in range(max_epochs):\n",
    "            \n",
    "            batch_X = X[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "            batch_y = y[batch_index * batch_size:(batch_index + 1) * batch_size]\n",
    "            batch_index += 1\n",
    "            \n",
    "            if batch_index * batch_size >= len(X):\n",
    "                batch_index = 0\n",
    "            \n",
    "            aa, zz = self.forward(batch_X)\n",
    "            cost, deltas, errors = self.backpropagation(learning_rate, batch_y, aa, zz)\n",
    "\n",
    "            for j in range(len(self.weights)):\n",
    "                self.weights[j] += learning_rate * aa[j].T @ deltas[-(j + 1)]\n",
    "                self.biases[j] += learning_rate * np.mean(deltas[-(j + 1)])\n",
    "\n",
    "            costs.append(cost / batch_size)\n",
    "            \n",
    "            epochs += 1\n",
    "            \n",
    "            if (cost / batch_size < max_error):\n",
    "                break\n",
    "\n",
    "            if i % 1000 == 0:\n",
    "                print(f'Iteration: {i}, error: {cost / batch_size}')\n",
    "                \n",
    "        return costs, epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, error: 0.7587876471239032\n",
      "Iteration: 1000, error: 0.23227497758181062\n",
      "Epochs: 1859\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 15), (15, 10)]\n",
    "\n",
    "network = Network(layer_shapes=layer_shapes, function='relu')\n",
    "\n",
    "X = []\n",
    "for X_matrix in train_X:\n",
    "    X.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X = np.array(X)\n",
    "    \n",
    "labels = []\n",
    "for y in train_y:\n",
    "    label = np.zeros(10)\n",
    "    label[y] = 1\n",
    "    labels.append(label)\n",
    "labels = np.array(labels)\n",
    "\n",
    "costs, epochs = network.train(X, \n",
    "              labels, \n",
    "              learning_rate=0.1, \n",
    "              max_epochs=10000,\n",
    "              batch_size=64,\n",
    "              max_error=0.1)\n",
    "\n",
    "print(f'Epochs: {epochs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.31%\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for X_matrix in test_X:\n",
    "    X.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X = np.array(X)\n",
    "\n",
    "z = network.forward(X, predict=True)\n",
    "\n",
    "sum = 0\n",
    "for z_i, label_i in zip(z, test_y):\n",
    "    if Network.get_result(z_i) == label_i:\n",
    "        sum +=1\n",
    "        \n",
    "print(f'Accuracy: {round(sum / len(z) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for X_matrix in train_X:\n",
    "    X.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X = np.array(X, dtype=np.float128)\n",
    "    \n",
    "labels = []\n",
    "for y in train_y:\n",
    "    label = np.zeros(10)\n",
    "    label[y] = 1\n",
    "    labels.append(label)\n",
    "labels = np.array(labels, dtype=np.float128)\n",
    "\n",
    "X_test = []\n",
    "for X_matrix in test_X[0:-3000]:\n",
    "    X_test.append(Network.normalize(X_matrix.reshape(784)))\n",
    "X_test = np.array(X_test, dtype=np.float128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2 , Epochs: 1310.8 , Accuracy: 45.06\n",
      "Batch: 4 , Epochs: 1841.2 , Accuracy: 56.82\n",
      "Batch: 8 , Epochs: 3315.2 , Accuracy: 61.73\n",
      "Batch: 16 , Epochs: 4941.4 , Accuracy: 68.46\n",
      "Batch: 32 , Epochs: 6907.2 , Accuracy: 72.24\n",
      "Batch: 64 , Epochs: 6752.2 , Accuracy: 71.25\n",
      "Batch: 128 , Epochs: 9780.6 , Accuracy: 73.27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1310.8</td>\n",
       "      <td>45.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1841.2</td>\n",
       "      <td>56.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>3315.2</td>\n",
       "      <td>61.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>4941.4</td>\n",
       "      <td>68.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>6907.2</td>\n",
       "      <td>72.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>64.0</td>\n",
       "      <td>6752.2</td>\n",
       "      <td>71.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>128.0</td>\n",
       "      <td>9780.6</td>\n",
       "      <td>73.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch  Epochs  Accuracy\n",
       "0    2.0  1310.8     45.06\n",
       "1    4.0  1841.2     56.82\n",
       "2    8.0  3315.2     61.73\n",
       "3   16.0  4941.4     68.46\n",
       "4   32.0  6907.2     72.24\n",
       "5   64.0  6752.2     71.25\n",
       "6  128.0  9780.6     73.27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Batch Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 15), (15, 10)]\n",
    "batches = [2, 4, 8, 16, 32, 64, 128]\n",
    "learning_rate = 0.1\n",
    "\n",
    "df = pd.DataFrame(columns=['Batch', 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for batch in batches:\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        network = Network(layer_shapes=layer_shapes, function=function)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=learning_rate, \n",
    "                      max_epochs=10000,\n",
    "                      batch_size=batch,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Batch:', batch, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Batch': batch, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-batch-size-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1 , Epochs: 10000.0 , Accuracy: 66.88\n",
      "Learning rate: 0.2 , Epochs: 6691.4 , Accuracy: 71.3\n",
      "Learning rate: 0.3 , Epochs: 4008.8 , Accuracy: 70.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-34c62e208ec4>:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.4 , Epochs: 5157.8 , Accuracy: 68.56\n",
      "Learning rate: 0.5 , Epochs: 4589.2 , Accuracy: 67.76\n",
      "Learning rate: 0.6 , Epochs: 2433.4 , Accuracy: 71.53\n",
      "Learning rate: 0.7 , Epochs: 5157.2 , Accuracy: 66.3\n",
      "Learning rate: 0.8 , Epochs: 4966.2 , Accuracy: 67.56\n",
      "Learning rate: 0.9 , Epochs: 1585.6 , Accuracy: 71.28\n",
      "Learning rate: 1.0 , Epochs: 1738.0 , Accuracy: 70.71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>66.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>6691.4</td>\n",
       "      <td>71.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>4008.8</td>\n",
       "      <td>70.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>5157.8</td>\n",
       "      <td>68.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>4589.2</td>\n",
       "      <td>67.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>2433.4</td>\n",
       "      <td>71.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>5157.2</td>\n",
       "      <td>66.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4966.2</td>\n",
       "      <td>67.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1585.6</td>\n",
       "      <td>71.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1738.0</td>\n",
       "      <td>70.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Learning rate   Epochs  Accuracy\n",
       "0            0.1  10000.0     66.88\n",
       "1            0.2   6691.4     71.30\n",
       "2            0.3   4008.8     70.61\n",
       "3            0.4   5157.8     68.56\n",
       "4            0.5   4589.2     67.76\n",
       "5            0.6   2433.4     71.53\n",
       "6            0.7   5157.2     66.30\n",
       "7            0.8   4966.2     67.56\n",
       "8            0.9   1585.6     71.28\n",
       "9            1.0   1738.0     70.71"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test learning rate Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 20), (20, 15), (15, 10)]\n",
    "learning_rates = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "df = pd.DataFrame(columns=['Learning rate', 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        network = Network(layer_shapes=layer_shapes, function=function)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=learning_rate, \n",
    "                      max_epochs=10000,\n",
    "                      batch_size=32,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Learning rate:', learning_rate, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Learning rate': learning_rate, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-learning-rate-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer size: 1 , Epochs: 10000.0 , Accuracy: 16.97\n",
      "Layer size: 2 , Epochs: 10000.0 , Accuracy: 26.33\n",
      "Layer size: 3 , Epochs: 10000.0 , Accuracy: 30.52\n",
      "Layer size: 4 , Epochs: 10000.0 , Accuracy: 28.88\n",
      "Layer size: 5 , Epochs: 10000.0 , Accuracy: 41.66\n",
      "Layer size: 6 , Epochs: 10000.0 , Accuracy: 49.38\n",
      "Layer size: 7 , Epochs: 10000.0 , Accuracy: 51.03\n",
      "Layer size: 8 , Epochs: 10000.0 , Accuracy: 56.15\n",
      "Layer size: 9 , Epochs: 10000.0 , Accuracy: 59.17\n",
      "Layer size: 10 , Epochs: 9438.2 , Accuracy: 69.37\n",
      "Layer size: 20 , Epochs: 4234.8 , Accuracy: 72.72\n",
      "Layer size: 30 , Epochs: 3041.2 , Accuracy: 72.95\n",
      "Layer size: 40 , Epochs: 1728.4 , Accuracy: 70.02\n",
      "Layer size: 50 , Epochs: 1694.2 , Accuracy: 70.5\n",
      "Layer size: 100 , Epochs: 1185.0 , Accuracy: 69.07\n",
      "Layer size: 200 , Epochs: 972.4 , Accuracy: 68.8\n",
      "Layer size: 300 , Epochs: 819.8 , Accuracy: 65.13\n",
      "Layer size: 400 , Epochs: 689.2 , Accuracy: 65.35\n",
      "Layer size: 500 , Epochs: 651.4 , Accuracy: 64.35\n",
      "Layer size: 600 , Epochs: 680.0 , Accuracy: 67.02\n",
      "Layer size: 700 , Epochs: 593.4 , Accuracy: 63.51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>16.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>26.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>30.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>28.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>41.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>49.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>51.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>56.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>59.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9438.2</td>\n",
       "      <td>69.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4234.8</td>\n",
       "      <td>72.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30.0</td>\n",
       "      <td>3041.2</td>\n",
       "      <td>72.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40.0</td>\n",
       "      <td>1728.4</td>\n",
       "      <td>70.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1694.2</td>\n",
       "      <td>70.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>69.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200.0</td>\n",
       "      <td>972.4</td>\n",
       "      <td>68.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>300.0</td>\n",
       "      <td>819.8</td>\n",
       "      <td>65.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>400.0</td>\n",
       "      <td>689.2</td>\n",
       "      <td>65.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>500.0</td>\n",
       "      <td>651.4</td>\n",
       "      <td>64.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>67.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>700.0</td>\n",
       "      <td>593.4</td>\n",
       "      <td>63.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer size   Epochs  Accuracy\n",
       "0          1.0  10000.0     16.97\n",
       "1          2.0  10000.0     26.33\n",
       "2          3.0  10000.0     30.52\n",
       "3          4.0  10000.0     28.88\n",
       "4          5.0  10000.0     41.66\n",
       "5          6.0  10000.0     49.38\n",
       "6          7.0  10000.0     51.03\n",
       "7          8.0  10000.0     56.15\n",
       "8          9.0  10000.0     59.17\n",
       "9         10.0   9438.2     69.37\n",
       "10        20.0   4234.8     72.72\n",
       "11        30.0   3041.2     72.95\n",
       "12        40.0   1728.4     70.02\n",
       "13        50.0   1694.2     70.50\n",
       "14       100.0   1185.0     69.07\n",
       "15       200.0    972.4     68.80\n",
       "16       300.0    819.8     65.13\n",
       "17       400.0    689.2     65.35\n",
       "18       500.0    651.4     64.35\n",
       "19       600.0    680.0     67.02\n",
       "20       700.0    593.4     63.51"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Hidden Layer Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 600, 700]\n",
    "\n",
    "df = pd.DataFrame(columns=['Layer size', 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for layer_size in layer_sizes:\n",
    "    \n",
    "    layer_shapes=[(784, layer_size), (layer_size, 10)]\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        network = Network(layer_shapes=layer_shapes, function='sigmoid')\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=0.1, \n",
    "                      max_epochs=10000,\n",
    "                      batch_size=32,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Layer size:', layer_size, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Layer size': layer_size, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-layer-size-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights' range: (-0.01, 0.01) , Epochs: 10000.0 , Accuracy: 70.2\n",
      "Weights' range: (-0.05, 0.05) , Epochs: 8436.4 , Accuracy: 75.44\n",
      "Weights' range: (-0.1, 0.1) , Epochs: 7621.8 , Accuracy: 74.71\n",
      "Weights' range: (-0.2, 0.2) , Epochs: 7465.0 , Accuracy: 75.0\n",
      "Weights' range: (-0.3, 0.3) , Epochs: 6885.2 , Accuracy: 75.14\n",
      "Weights' range: (-0.4, 0.4) , Epochs: 7222.4 , Accuracy: 74.59\n",
      "Weights' range: (-0.5, 0.5) , Epochs: 7307.4 , Accuracy: 73.72\n",
      "Weights' range: (-1, 1) , Epochs: 5905.0 , Accuracy: 72.42\n",
      "Weights' range: (-2, 2) , Epochs: 5422.6 , Accuracy: 66.69\n",
      "Weights' range: (-3, 3) , Epochs: 5596.0 , Accuracy: 63.97\n",
      "Weights' range: (-4, 4) , Epochs: 8577.8 , Accuracy: 61.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-80f134aa1ce8>:45: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights' range: (-5, 5) , Epochs: 10000.0 , Accuracy: 57.74\n",
      "Weights' range: (-10, 10) , Epochs: 8747.0 , Accuracy: 44.34\n",
      "Weights' range: (-20, 20) , Epochs: 10000.0 , Accuracy: 30.51\n",
      "Weights' range: (-30, 30) , Epochs: 10000.0 , Accuracy: 35.48\n",
      "Weights' range: (-40, 40) , Epochs: 10000.0 , Accuracy: 33.11\n",
      "Weights' range: (-50, 50) , Epochs: 10000.0 , Accuracy: 33.06\n",
      "Weights' range: (-60, 60) , Epochs: 10000.0 , Accuracy: 32.09\n",
      "Weights' range: (-70, 70) , Epochs: 10000.0 , Accuracy: 33.58\n",
      "Weights' range: (-80, 80) , Epochs: 10000.0 , Accuracy: 39.63\n",
      "Weights' range: (-90, 90) , Epochs: 10000.0 , Accuracy: 32.9\n",
      "Weights' range: (-100, 100) , Epochs: 10000.0 , Accuracy: 32.8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Weights' range:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>70.20</td>\n",
       "      <td>(-0.01, 0.01)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8436.4</td>\n",
       "      <td>75.44</td>\n",
       "      <td>(-0.05, 0.05)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7621.8</td>\n",
       "      <td>74.71</td>\n",
       "      <td>(-0.1, 0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7465.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>(-0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6885.2</td>\n",
       "      <td>75.14</td>\n",
       "      <td>(-0.3, 0.3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7222.4</td>\n",
       "      <td>74.59</td>\n",
       "      <td>(-0.4, 0.4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7307.4</td>\n",
       "      <td>73.72</td>\n",
       "      <td>(-0.5, 0.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5905.0</td>\n",
       "      <td>72.42</td>\n",
       "      <td>(-1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5422.6</td>\n",
       "      <td>66.69</td>\n",
       "      <td>(-2, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5596.0</td>\n",
       "      <td>63.97</td>\n",
       "      <td>(-3, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8577.8</td>\n",
       "      <td>61.89</td>\n",
       "      <td>(-4, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>57.74</td>\n",
       "      <td>(-5, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8747.0</td>\n",
       "      <td>44.34</td>\n",
       "      <td>(-10, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>30.51</td>\n",
       "      <td>(-20, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>35.48</td>\n",
       "      <td>(-30, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>33.11</td>\n",
       "      <td>(-40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>33.06</td>\n",
       "      <td>(-50, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>32.09</td>\n",
       "      <td>(-60, 60)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>33.58</td>\n",
       "      <td>(-70, 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>39.63</td>\n",
       "      <td>(-80, 80)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>32.90</td>\n",
       "      <td>(-90, 90)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>32.80</td>\n",
       "      <td>(-100, 100)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Layer size   Epochs  Accuracy Weights' range:\n",
       "0          NaN  10000.0     70.20   (-0.01, 0.01)\n",
       "1          NaN   8436.4     75.44   (-0.05, 0.05)\n",
       "2          NaN   7621.8     74.71     (-0.1, 0.1)\n",
       "3          NaN   7465.0     75.00     (-0.2, 0.2)\n",
       "4          NaN   6885.2     75.14     (-0.3, 0.3)\n",
       "5          NaN   7222.4     74.59     (-0.4, 0.4)\n",
       "6          NaN   7307.4     73.72     (-0.5, 0.5)\n",
       "7          NaN   5905.0     72.42         (-1, 1)\n",
       "8          NaN   5422.6     66.69         (-2, 2)\n",
       "9          NaN   5596.0     63.97         (-3, 3)\n",
       "10         NaN   8577.8     61.89         (-4, 4)\n",
       "11         NaN  10000.0     57.74         (-5, 5)\n",
       "12         NaN   8747.0     44.34       (-10, 10)\n",
       "13         NaN  10000.0     30.51       (-20, 20)\n",
       "14         NaN  10000.0     35.48       (-30, 30)\n",
       "15         NaN  10000.0     33.11       (-40, 40)\n",
       "16         NaN  10000.0     33.06       (-50, 50)\n",
       "17         NaN  10000.0     32.09       (-60, 60)\n",
       "18         NaN  10000.0     33.58       (-70, 70)\n",
       "19         NaN  10000.0     39.63       (-80, 80)\n",
       "20         NaN  10000.0     32.90       (-90, 90)\n",
       "21         NaN  10000.0     32.80     (-100, 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Initial Weight values\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "w_max_values = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 1, 2, 3, 4, 5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"Weights' range\", 'Epochs', 'Accuracy'])\n",
    "function = 'sigmoid'\n",
    "\n",
    "for max_value in w_max_values:\n",
    "    \n",
    "    layer_shapes=[(784, 15), (15, 10)]\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        network = Network(layer_shapes=layer_shapes, function='sigmoid', max_value=max_value)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=0.1, \n",
    "                      max_epochs=10000,\n",
    "                      batch_size=32,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print(\"Weights' range:\", (-max_value, max_value), ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({\"Weights' range:\": (-max_value, max_value), 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-weights-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, error: 0.7587876471239032\n",
      "Iteration: 1000, error: 0.23227497758181057\n",
      "Iteration: 0, error: 0.8361567392133491\n",
      "Iteration: 1000, error: 0.21374314212147152\n",
      "Iteration: 0, error: 0.6916539050901342\n",
      "Iteration: 1000, error: 0.24216882457404768\n",
      "Iteration: 0, error: 0.7959780376256106\n",
      "Iteration: 1000, error: 0.7495916906677739\n",
      "Iteration: 2000, error: 0.5369314542569128\n",
      "Iteration: 3000, error: 0.5447214734078016\n",
      "Iteration: 4000, error: 0.5197941172824602\n",
      "Iteration: 0, error: 0.8112129029570698\n",
      "Iteration: 1000, error: 0.5672622030068897\n",
      "Iteration: 2000, error: 0.5536046769430132\n",
      "Iteration: 3000, error: 0.5560127331183259\n",
      "Iteration: 4000, error: 0.5358670543441755\n",
      "Batch: 2 , Epochs: 3118.6 , Accuracy: 44.46\n",
      "Iteration: 0, error: 0.8203965150838686\n",
      "Iteration: 1000, error: 0.6776453710662813\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4e18b7bae21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         costs, epoch = network.train(X, \n\u001b[0m\u001b[1;32m     24\u001b[0m                       \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                       \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b77d33e959e0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, learning_rate, batch_size, max_epochs, max_error)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-b77d33e959e0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, predict)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m \u001b[0;31m# + b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Test Batch Size\n",
    "\n",
    "np.random.seed(243)\n",
    "random.seed(243)\n",
    "\n",
    "layer_shapes=[(784, 15), (15, 10)]\n",
    "batches = [2, 4, 8, 16, 32, 64, 128]\n",
    "learning_rate = 0.1\n",
    "\n",
    "df = pd.DataFrame(columns=['Batch', 'Epochs', 'Accuracy'])\n",
    "function = 'relu'\n",
    "\n",
    "for batch in batches:\n",
    "    \n",
    "    learning_times = []\n",
    "    epochs = []\n",
    "    errors = []\n",
    "    accs = []\n",
    "    \n",
    "    for i in range(5):\n",
    "        network = Network(layer_shapes=layer_shapes, function=function)\n",
    "\n",
    "        costs, epoch = network.train(X, \n",
    "                      labels, \n",
    "                      learning_rate=0.1, \n",
    "                      max_epochs=5000,\n",
    "                      batch_size=64,\n",
    "                      max_error=0.1)\n",
    "\n",
    "        z = network.forward(X_test, predict=True)\n",
    "\n",
    "        sum = 0\n",
    "        for z_i, label_i in zip(z, test_y[0:-3000]):\n",
    "            if Network.get_result(z_i) == label_i:\n",
    "                sum +=1\n",
    "                \n",
    "        epochs.append(epoch)\n",
    "        accs.append(round(sum / len(z) * 100, 2))\n",
    "\n",
    "    print('Batch:', batch, ', Epochs:', round(np.mean(epochs), 2), ', Accuracy:', round(np.mean(accs), 2))\n",
    "    df = df.append({'Batch': batch, 'Epochs': round(np.mean(epochs), 2), 'Accuracy': round(np.mean(accs), 2)}, ignore_index=True)\n",
    "    \n",
    "display(df)\n",
    "df.to_csv(f'./Results/{function}-batch-size-testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
